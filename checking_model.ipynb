{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atrichaudhuri/endovis18-vqa/blob/main/checking_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pU4iPZR0ucs",
        "outputId": "824884f5-a6a5-4e28-c7db-11f5f512d739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SurgicalGPT'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 89 (delta 42), reused 82 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (89/89), 749.26 KiB | 1.17 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lalithjets/SurgicalGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SWZYckbo1Wuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70bc66a6-f241-4dd9-efd3-b91e096a76e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        }
      ],
      "source": [
        "# Installing required dependencies\n",
        "!pip -q install transformers\n",
        "!pip -q install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing by loading the model only\n",
        "# Type 1\n",
        "# import math\n",
        "# import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import transformers\n",
        "# from timm.models import create_model\n",
        "from transformers import  VisualBertConfig, GPT2Config\n",
        "from transformers import VisualBertModel, GPT2Model, ViTModel, SwinModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class EFVLEGPT2SwinClassification(nn.Module):\n",
        "    def __init__(self, num_class = 12, model_subver = 'v0', vis_pos_emb = None):\n",
        "        super(EFVLEGPT2SwinClassification, self).__init__()\n",
        "        '''\n",
        "        v0: visual embedding : Default patch1 + embedding form VB + GPT2 decoder\n",
        "        v1: visual embedding : Default patch1 + GPT2 decoder\n",
        "        '''\n",
        "\n",
        "        self.sub_ver = model_subver\n",
        "        self.vis_pos_emb = vis_pos_emb\n",
        "\n",
        "        ## image processing\n",
        "        self.img_feature_extractor = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "\n",
        "        ## Visual_embedding\n",
        "        # visual bert embedding\n",
        "        if self.sub_ver == \"v0\":\n",
        "            VB_config = VisualBertConfig.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
        "            VB_config.visual_embedding_dim = 768\n",
        "            visualbert = VisualBertModel(config=VB_config)\n",
        "            self.visual_embedder = visualbert.embeddings.visual_projection\n",
        "\n",
        "        ## Question_embedding\n",
        "        question_embedder = model = transformers.LlamaForCausalLM.from_pretrained('chaoyi-wu/PMC_LLAMA_7B' ,offload_folder=\"offload\", offload_state_dict = True, device_map=\"auto\")\n",
        "        self.question_embedder = question_embedder.wte\n",
        "\n",
        "        ## GPT2 visual_cotext_aware_decoder\n",
        "        self.VCAdecoder = model = transformers.LlamaForCausalLM.from_pretrained('chaoyi-wu/PMC_LLAMA_7B' ,offload_folder=\"offload\", offload_state_dict = True, device_map=\"auto\")\n",
        "        # for name,child in self.VCAdecoder.h.named_children():\n",
        "        #     child.mlp._modules['act'] = SwiGLU()\n",
        "        # self.VCAdecoder.wte = nn.Embedding(2, 768)  # later used for position embedding\n",
        "\n",
        "        ## intermediate_layers\n",
        "        self.intermediate_layer = nn.Linear(768, 512)  #(512+768)\n",
        "        self.LayerNorm = nn.BatchNorm1d(512)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        ## classifier\n",
        "        self.classifier = nn.Linear(512, num_class)\n",
        "\n",
        "    def forward(self, input, img):\n",
        "\n",
        "        ## image encoder features\n",
        "        img['pixel_values'] = img['pixel_values'].to(device)\n",
        "        img_feature = self.img_feature_extractor(**img)\n",
        "\n",
        "\n",
        "        ## visual Embedding : id type 1, pos: zero / incremental\n",
        "        if self.sub_ver == 'v0':\n",
        "            visual_embeds = self.visual_embedder(img_feature[0])\n",
        "        elif self.sub_ver == 'v1':\n",
        "            visual_embeds = img_feature[0]\n",
        "\n",
        "        # if self.training is True:\n",
        "        #     sigma = torch.tensor(np.random.uniform(0, 0.4, visual_embeds.size()[1])).to(device)\n",
        "        #     smoothing_layer = get_gaussian_filter(ksize=3, sigma=sigma, channels=visual_embeds.size()[1]).to(device)\n",
        "        #     visual_embeds = smoothing_layer(visual_embeds)\n",
        "\n",
        "        visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.float)\n",
        "        visual_attention_mask = visual_attention_mask.to(device)\n",
        "\n",
        "        if self.vis_pos_emb == 'zeroes':\n",
        "            visual_id_type = torch.ones(*visual_embeds.size()[:-1], dtype=torch.long, device=device)\n",
        "            visual_position_id = torch.zeros(*visual_embeds.size()[:-1], dtype=torch.long, device=device)\n",
        "        elif self.vis_pos_emb == 'pos':\n",
        "            visual_id_type = torch.ones(*visual_embeds.size()[:-1], dtype=torch.long, device=device)\n",
        "            visual_position_id = torch.arange(0,visual_embeds.size()[1])\n",
        "            visual_position_id = torch.unsqueeze(visual_position_id,0)\n",
        "            visual_position_id = visual_position_id.repeat(visual_embeds.size()[0], 1)\n",
        "            visual_position_id = visual_position_id.to(device)\n",
        "\n",
        "\n",
        "        ## question embedding: id type 0, pose incremental\n",
        "        input['input_ids'] = input['input_ids'].to(device)\n",
        "        input['attention_mask'] = input['attention_mask'].to(device)\n",
        "\n",
        "        question_embeds = self.question_embedder(input['input_ids'])\n",
        "        question_attention_mask = input['attention_mask']\n",
        "\n",
        "        if self.vis_pos_emb == 'zeroes' or self.vis_pos_emb == 'pos':\n",
        "            question_id_type = torch.zeros(*question_embeds.size()[:-1], dtype=torch.long, device=device)\n",
        "            question_position_id = torch.arange(0,question_embeds.size()[1])\n",
        "            question_position_id = torch.unsqueeze(question_position_id,0)\n",
        "            question_position_id = question_position_id.repeat(question_embeds.size()[0], 1)\n",
        "            question_position_id = question_position_id.to(device)\n",
        "\n",
        "\n",
        "        ## combine visual and question embeds\n",
        "        ## vision first\n",
        "        # inputs_embeds = torch.cat((visual_embeds, question_embeds), dim=1)\n",
        "        # attention_mask = torch.cat((visual_attention_mask, question_attention_mask), dim=1)\n",
        "\n",
        "        # if self.vis_pos_emb == 'zeroes' or self.vis_pos_emb == 'pos':\n",
        "        #     token_type_ids = torch.cat((visual_id_type, question_id_type), dim=1)\n",
        "        #     position_ids = torch.cat((visual_position_id, question_position_id), dim=1)\n",
        "\n",
        "        ## question first\n",
        "        inputs_embeds = torch.cat((question_embeds, visual_embeds), dim=1)\n",
        "        attention_mask = torch.cat((question_attention_mask, visual_attention_mask), dim=1)\n",
        "\n",
        "        if self.vis_pos_emb == 'zeroes' or self.vis_pos_emb == 'pos':\n",
        "            token_type_ids = torch.cat((question_id_type, visual_id_type), dim=1)\n",
        "            position_ids = torch.cat((question_position_id, visual_position_id), dim=1)\n",
        "\n",
        "        ## VCA_GPT2 decoder\n",
        "        if self.vis_pos_emb == 'zeroes' or self.vis_pos_emb == 'pos':\n",
        "            decoder_output = self.VCAdecoder(inputs_embeds=inputs_embeds, attention_mask=attention_mask, position_ids = position_ids, token_type_ids = token_type_ids)\n",
        "        else:\n",
        "            decoder_output = self.VCAdecoder(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
        "        decoder_output = decoder_output.last_hidden_state.swapaxes(1,2)\n",
        "        decoder_output = F.adaptive_avg_pool1d(decoder_output,1)\n",
        "        decoder_output = decoder_output.swapaxes(1,2).squeeze(1)\n",
        "\n",
        "        ## intermediate layers\n",
        "        out =self.intermediate_layer(decoder_output)\n",
        "        out = self.LayerNorm(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        ## classifier\n",
        "        out = self.classifier(out)\n",
        "        # print(out.size())\n",
        "        return out"
      ],
      "metadata": {
        "id": "Wj1Az0gsWW6E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EFVLEGPT2SwinClassification(num_class = 12, model_subver = 'v0', vis_pos_emb = None)"
      ],
      "metadata": {
        "id": "FeAiWe5YTQon",
        "outputId": "297b13bf-efe3-4af7-8671-b59fd97a88dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3ed8ebca5b6b49fd93acca671b25322f",
            "2819439abbd04c6dbc466794c98da1a2",
            "dcd06ea2cc24488e813abaa50deeb9c6",
            "9b59e685617b4a63a385d602ac79dcf3",
            "2fc1942a4f17426f93ad656b8bc1ef5d",
            "3dc67eeecd4b4f6199861aa96ff2bfe0",
            "6f162756c78a4f1085cec09bd6de107e",
            "cbbccca6fcf74c87b179142cfaebf355",
            "b4b179dbadd048668eadb81c09658616",
            "c05e162b677e4a3f80ebcdb2f728f74a",
            "da78fd8723e04e1ea77899bf3c9aeb22"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ed8ebca5b6b49fd93acca671b25322f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUWo9HnVTcRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ed8ebca5b6b49fd93acca671b25322f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2819439abbd04c6dbc466794c98da1a2",
              "IPY_MODEL_dcd06ea2cc24488e813abaa50deeb9c6",
              "IPY_MODEL_9b59e685617b4a63a385d602ac79dcf3"
            ],
            "layout": "IPY_MODEL_2fc1942a4f17426f93ad656b8bc1ef5d"
          }
        },
        "2819439abbd04c6dbc466794c98da1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dc67eeecd4b4f6199861aa96ff2bfe0",
            "placeholder": "​",
            "style": "IPY_MODEL_6f162756c78a4f1085cec09bd6de107e",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "dcd06ea2cc24488e813abaa50deeb9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbbccca6fcf74c87b179142cfaebf355",
            "max": 71813,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4b179dbadd048668eadb81c09658616",
            "value": 71813
          }
        },
        "9b59e685617b4a63a385d602ac79dcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c05e162b677e4a3f80ebcdb2f728f74a",
            "placeholder": "​",
            "style": "IPY_MODEL_da78fd8723e04e1ea77899bf3c9aeb22",
            "value": " 71.8k/71.8k [00:00&lt;00:00, 236kB/s]"
          }
        },
        "2fc1942a4f17426f93ad656b8bc1ef5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dc67eeecd4b4f6199861aa96ff2bfe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f162756c78a4f1085cec09bd6de107e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbbccca6fcf74c87b179142cfaebf355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4b179dbadd048668eadb81c09658616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c05e162b677e4a3f80ebcdb2f728f74a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da78fd8723e04e1ea77899bf3c9aeb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}