{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atrichaudhuri/endovis18-vqa/blob/main/endovis18_vqa_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pU4iPZR0ucs",
        "outputId": "a462c1f7-056a-41d9-914a-c4e304155c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SurgicalGPT'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 89 (delta 42), reused 82 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (89/89), 749.26 KiB | 962.00 KiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lalithjets/SurgicalGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SWZYckbo1Wuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53703e4-17d2-4214-98a8-1d49f9ab6a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installing required dependencies\n",
        "!pip -q install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7wl6PSm0xF9",
        "outputId": "0e092c9d-bb36-4b39-b073-a8da76ca0f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1K5YnSPMPvn2x1gtRAw2ZfxIqoIo2DX3I\n",
            "To: /content/EndoVis-18-VQA.zip\n",
            "100% 2.64G/2.64G [00:29<00:00, 90.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Downloading the VQA EndoVis18 Dataset\n",
        "!gdown --id 1K5YnSPMPvn2x1gtRAw2ZfxIqoIo2DX3I\n",
        "\n",
        "# Unzipping the VQA EndoVis18 Dataset\\\n",
        "!unzip -q EndoVis-18-VQA.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset path correction as repo\n",
        "!mv -f EndoVis-18-VQA /content/SurgicalGPT/dataset\n",
        "seq_all = [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16]\n",
        "for sed in seq_all:\n",
        "    !mv /content/SurgicalGPT/dataset/EndoVis-18-VQA/seq_{sed}/vqa/Images /content/SurgicalGPT/dataset/EndoVis-18-VQA/seq_{sed}/left_frames"
      ],
      "metadata": {
        "id": "NtzbQyOoNypt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcMJ5Prm0_dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128d1862-f832-4054-fe70-7f0e56144c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SurgicalGPT\n",
            "2023-09-30 21:13:34.850307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "efvlegpt2Swin v1 zeroes m18 cat1 1e-05 checkpoints/efvlegpt2Swin/m18_v1_z_qf_\n",
            "device = cuda\n",
            "Downloading (…)olve/main/vocab.json: 100% 1.04M/1.04M [00:00<00:00, 2.20MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 50.0MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 665/665 [00:00<00:00, 3.68MB/s]\n",
            "Downloading (…)rocessor_config.json: 100% 255/255 [00:00<00:00, 1.25MB/s]\n",
            "Total files: 1560 | Total question: 9014\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Total files: 447 | Total question: 2769\n",
            "Downloading (…)lve/main/config.json: 100% 71.8k/71.8k [00:00<00:00, 59.7MB/s]\n",
            "Downloading model.safetensors: 100% 113M/113M [00:00<00:00, 357MB/s] \n",
            "Downloading model.safetensors: 100% 548M/548M [00:01<00:00, 283MB/s]\n",
            "model params:  190960524\n",
            "Train: epoch: 1 loss: 351.756564 | Acc: 0.526181 | Precision: 0.250180 | Recall: 0.214734 | FScore: 0.212207\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Test: epoch: 1 loss: 71.497536 | Acc: 0.612134 | Precision: 0.739757 | Recall: 0.328198 | FScore: 0.312041\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train: epoch: 2 loss: 189.943233 | Acc: 0.714999 | Precision: 0.773943 | Recall: 0.360313 | FScore: 0.374940\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Test: epoch: 2 loss: 69.024135 | Acc: 0.622969 | Precision: 0.771869 | Recall: 0.333405 | FScore: 0.322119\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train: epoch: 3 loss: 157.719585 | Acc: 0.764477 | Precision: 0.810256 | Recall: 0.472680 | FScore: 0.494839\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Running the training loop with all arguments\n",
        "%cd /content/SurgicalGPT\n",
        "import os\n",
        "os.makedirs('checkpoints/efvlegpt2Swin', exist_ok=True)\n",
        "!python train.py \\\n",
        "--lr=0.00001 \\\n",
        "--checkpoint_dir='checkpoints/efvlegpt2Swin/m18_v1_z_qf_' \\\n",
        "--dataset_type='m18' \\\n",
        "--tokenizer_ver='gpt2v1' \\\n",
        "--model_ver='efvlegpt2Swin' \\\n",
        "--model_subver='v1' \\\n",
        "--vis_pos_emb='zeroes'\\\n",
        "--batch_size=40\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wj1Az0gsWW6E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}